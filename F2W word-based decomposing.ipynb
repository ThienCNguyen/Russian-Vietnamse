{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"F2W word-based decomposing.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"c5Z90uxDxPFJ"},"source":["#try:\n","#    import sentencepiece as spm\n","#except ImportError as e:\n","#    os.system('pip install sentencepiece')\n","#    import sentencepiece as spm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cPltHwUmdImy"},"source":["# Set the random seeds for reproducability.\n","SEED = 2020\n","#SEED = 2021\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9HAf9lyx_Q74","executionInfo":{"status":"ok","timestamp":1594183031423,"user_tz":-420,"elapsed":1899,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"143a7ac9-6dc1-47d4-8dc9-74dc5bba82dd","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P1_qC_Jcuuon"},"source":["# DEFINITIONS"]},{"cell_type":"code","metadata":{"id":"zF0QYPWIYuF_"},"source":["class Subword():\n","    def __init__(self, lang, vocab_size):\n","        \"\"\"\n","        recomended: vocab_size = 2000 for lang = vi, 4000 for lang = ru\n","        \"\"\"\n","        self.lang = lang\n","        self.vocab_size = vocab_size\n","        spm.SentencePieceTrainer.Train(f'--input=train.{lang} --model_prefix=vi --vocab_size={vocab_size} --model_type=unigram --character_coverage=1.0')\n","        self.sp = spm.SentencePieceProcessor()\n","        self.sp.Load(f\"{lang}.model\")\n","        \n","    def split_words(self, filename, new_filename):\n","        content = open(filename, 'r').read().splitlines()\n","        new_content = [' '.join(self.sp.EncodeAsPieces(line)) for line in content]\n","        open(new_filename, 'w').write('\\n'.join(new_content))\n","\n","    @staticmethod\n","    def join_pieces(pred_trgs, new_filename, type='bpe'):\n","        \"\"\"\n","        function joins pieces to form words\n","        input: pred_trgs, list of list of pieces\n","        input: new_filename, str\n","\n","        \"\"\"\n","        lines = []\n","        if type == 'unigram':\n","            for line in pred_trgs:\n","                y = ''.join(line)\n","                y = y.replace('▁', ' ')\n","                lines.append(y)\n","        else:\n","            for line in pred_trgs:\n","                y = ' '.join(line)\n","                y = y.replace('@@ ','')\n","                lines.append(y)\n","        open(new_filename, 'w').write('\\n'.join(lines))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rSgy8oneGYnQ"},"source":["## Data Center"]},{"cell_type":"markdown","metadata":{"id":"tLZm4O80Sy1R"},"source":["Creating test.ru file"]},{"cell_type":"code","metadata":{"id":"470fzbdcLov_"},"source":["dat = pd.read_csv('word.ru.tsv', sep='\\t')\n","print(dat.columns)\n","dat.iloc[:1500,0].to_csv('test.ru', sep='\\n', index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ljL7J74x_pE"},"source":["class DataCenter():\n","\n","    def __init__(self, ru_token_type='unigram', vi_token_type='unigram', SELECTED = np.array([1, 1, 1, 0, 0, 1, 1, 1]), device='cuda'):\n","        \"\"\"\n","        ru_token_type is one of {'unigram', 'bpe', 'word'}\n","        vi_token_type is one of {'unigram', 'bpe', 'syllable', 'word'}\n","        \"\"\"\n","        self.SELECTED = SELECTED\n","        s = str(SELECTED)\n","        self.name = ru_token_type + s.replace(\" \", \"\").replace(\"[\",\"\").replace(\"]\",\"\") + vi_token_type\n","        dat = pd.read_csv(f'{ru_token_type}.ru.tsv', sep='\\t')\n","        ru_names = list(dat.columns)\n","\n","        vi_data = pd.read_csv('new.vi.tsv', sep='\\t')[vi_token_type]\n","        dat['vi'] = vi_data\n","        dat = dat[ru_names+['vi']]\n","        dat.iloc[:1500,:].to_csv('test.tsv', sep='\\t', index=False, header=False)\n","        dat.iloc[1500:3000,:].to_csv('dev.tsv', sep='\\t', index=False, header=False)\n","        dat.iloc[3000:,:].to_csv('train.tsv', sep='\\t', index=False)\n","\n","        self.device = device\n","\n","        testfile, devfile, trainfile =  'test.tsv', 'dev.tsv', 'train.tsv'\n","\n","        #The model expects data to be fed in with the batch dimension first, so we use `batch_first = True`. \n","    \n","        field_names = list(pd.read_csv(trainfile,sep='\\t').columns)\n","\n","        self.field_sequence = [Field(tokenize = lambda x: x.split(' '), init_token = '<sos>', eos_token = '<eos>', lower = True, \n","                        batch_first = True) for _ in field_names]\n","        \n","        fields = list(zip(field_names, self.field_sequence))\n","\n","        self.mt_train = data.TabularDataset(\n","            path=trainfile, format='tsv',\n","            fields=fields)\n","        self.mt_dev = data.TabularDataset(\n","            path=devfile, format='tsv',\n","            fields=fields)\n","        self.mt_test = data.TabularDataset(\n","            path=testfile, format='tsv',\n","            fields=fields)\n","        \n","        for f in self.field_sequence:\n","            f.build_vocab(self.mt_train, min_freq = 2)\n","        \n","        self.SRC_PAD_IDX = self.field_sequence[0].vocab.stoi[self.field_sequence[0].pad_token]\n","        self.TRG_PAD_IDX = self.field_sequence[-1].vocab.stoi[self.field_sequence[-1].pad_token]\n","        self.src_lens = [len(field.vocab) for field in self.field_sequence[:-1]]\n","        self.trg_len = len(self.field_sequence[-1].vocab)\n","\n","        # Finally, we define the device and the data iterator.\n","        self.train_iterator = data.BucketIterator(\n","            dataset=self.mt_train, batch_size=128,\n","            sort_key=lambda x: data.interleave_keys(len(x.ru), len(x.vi)), device = device)\n","        self.valid_iterator = data.BucketIterator(\n","            dataset=self.mt_dev, batch_size=128,\n","            sort_key=lambda x: data.interleave_keys(len(x.ru), len(x.vi)), device = device)\n","    \n","    @staticmethod\n","    def detokenize(ifilename, ofilename):\n","        findlines = '_'\n","        replacelines = ' '\n","\n","        with open(ifilename,'r') as ifile, open(ofilename, 'w') as ofile:\n","            icontent = ifile.read()\n","            ocontent = icontent.replace(findlines, replacelines)\n","            ofile.write(ocontent)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"loS_AT9erBVr"},"source":["def detokenize(ifilename, ofilename):\n","\tfindlines = '_'\n","\treplacelines = ' '\n","\n","\twith open(ifilename,'r') as ifile, open(ofilename, 'w') as ofile:\n","\t\ticontent = ifile.read()\n","\t\tocontent = icontent.replace(findlines, replacelines)\n","\t\tofile.write(ocontent)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kPJcjj66KWnl"},"source":["def prepare_mt_datasets(trainfile, devfile, testfile):\n","    #The model expects data to be fed in with the batch dimension first, so we use `batch_first = True`. \n","    \n","    field_names = list(pd.read_csv(trainfile,sep='\\t').columns)\n","\n","    field_sequence = [Field(init_token = '<sos>', eos_token = '<eos>', lower = True, \n","                    batch_first = True) for _ in field_names]\n","    \n","    fields = list(zip(field_names,field_sequence))\n","\n","    mt_train = data.TabularDataset(\n","        path=trainfile, format='tsv',\n","        fields=fields)\n","    mt_dev = data.TabularDataset(\n","        path=devfile, format='tsv',\n","        fields=fields)\n","    mt_test = data.TabularDataset(\n","        path=testfile, format='tsv',\n","        fields=fields)\n","    \n","    for f in field_sequence:\n","        f.build_vocab(mt_train, min_freq = 2)\n","\n","    return field_sequence, mt_train, mt_dev, mt_test"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-vogZ6V5e-10"},"source":["## Transformer Model"]},{"cell_type":"markdown","metadata":{"id":"MU5cmCklGYnx"},"source":["### Encoder"]},{"cell_type":"code","metadata":{"id":"mejyCGfvGYnx"},"source":["class Encoder(nn.Module):\n","    \"\"\"\n","    this is an encoder incorporating input features\n","    \"\"\"\n","    def __init__(self,\n","                 input_dims, selected, \n","                 hid_dim, \n","                 n_layers, \n","                 n_heads, \n","                 pf_dim,\n","                 dropout, \n","                 device,\n","                 max_length = 100):\n","        super().__init__()\n","\n","        self.device = device\n","        #[subtag', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats']\n","\n","        sizes = [190, 22, 22, 22]\n","        temp = []\n","        j = 0\n","        for i,se in enumerate(selected):\n","            if se:\n","                temp.append(nn.Embedding(input_dims[i], sizes[j]))\n","                j += 1\n","        self.embeddings = nn.ModuleList(temp)\n","        \n","        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n","        \n","        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n","                                                  n_heads, \n","                                                  pf_dim,\n","                                                  dropout, \n","                                                  device) \n","                                     for _ in range(n_layers)])\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n","        \n","    def forward(self, src, s, src_mask):\n","        \n","        #src = [features, batch size, src len]\n","        #src_mask = [batch size, src len]\n","        \n","        batch_size = src[0].shape[0]\n","        src_len = src[0].shape[1]\n","        \n","        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","        \n","        selected_ifeatures = []\n","        j = 0\n","        for i,se in enumerate(s):\n","            if se:\n","                selected_ifeatures.append(self.embeddings[j](src[i]))\n","                j += 1\n","                \n","        #pos = [batch size, src len]\n","        src = torch.cat(selected_ifeatures, dim=2)\n","        #src = [batch size, src len, aggregate_input_dim]\n","        #src = [batch size, src len, hid dim]\n","        \n","        src = self.dropout((src * self.scale) + self.pos_embedding(pos))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        for layer in self.layers:\n","            src = layer(src, src_mask)\n","            \n","        #src = [batch size, src len, hid dim]\n","            \n","        return src"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j0KUOQeNGYnz"},"source":["### Encoder Layer"]},{"cell_type":"code","metadata":{"id":"LnyklRzsGYnz"},"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, \n","                 hid_dim, \n","                 n_heads, \n","                 pf_dim,  \n","                 dropout, \n","                 device):\n","        super().__init__()\n","        \n","        self.layer_norm = nn.LayerNorm(hid_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n","                                                                     pf_dim, \n","                                                                     dropout)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src, src_mask):\n","        \n","        #src = [batch size, src len, hid dim]\n","        #src_mask = [batch size, src len]\n","                \n","        #self attention\n","        _src, _ = self.self_attention(src, src, src, src_mask)\n","        \n","        #dropout, residual connection and layer norm\n","        src = self.layer_norm(src + self.dropout(_src))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        #positionwise feedforward\n","        _src = self.positionwise_feedforward(src)\n","        \n","        #dropout, residual and layer norm\n","        src = self.layer_norm(src + self.dropout(_src))\n","        \n","        #src = [batch size, src len, hid dim]\n","        \n","        return src"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q9P4NqDdGYn1"},"source":["### Mutli Head Attention Layer"]},{"cell_type":"code","metadata":{"id":"RtpOT9uFGYn2"},"source":["class MultiHeadAttentionLayer(nn.Module):\n","    def __init__(self, hid_dim, n_heads, dropout, device):\n","        super().__init__()\n","        \n","        assert hid_dim % n_heads == 0\n","        \n","        self.hid_dim = hid_dim\n","        self.n_heads = n_heads\n","        self.head_dim = hid_dim // n_heads\n","        \n","        self.fc_q = nn.Linear(hid_dim, hid_dim)\n","        self.fc_k = nn.Linear(hid_dim, hid_dim)\n","        self.fc_v = nn.Linear(hid_dim, hid_dim)\n","        \n","        self.fc_o = nn.Linear(hid_dim, hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n","        \n","    def forward(self, query, key, value, mask = None):\n","        \n","        batch_size = query.shape[0]\n","        \n","        #query = [batch size, query len, hid dim]\n","        #key = [batch size, key len, hid dim]\n","        #value = [batch size, value len, hid dim]\n","                \n","        Q = self.fc_q(query)\n","        K = self.fc_k(key)\n","        V = self.fc_v(value)\n","        \n","        #Q = [batch size, query len, hid dim]\n","        #K = [batch size, key len, hid dim]\n","        #V = [batch size, value len, hid dim]\n","                \n","        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n","        \n","        #Q = [batch size, n heads, query len, head dim]\n","        #K = [batch size, n heads, key len, head dim]\n","        #V = [batch size, n heads, value len, head dim]\n","                \n","        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n","        \n","        #energy = [batch size, n heads, query len, key len]\n","        \n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, -1e10)\n","        \n","        attention = torch.softmax(energy, dim = -1)\n","                \n","        #attention = [batch size, n heads, query len, key len]\n","                \n","        x = torch.matmul(self.dropout(attention), V)\n","        \n","        #x = [batch size, n heads, query len, head dim]\n","        \n","        x = x.permute(0, 2, 1, 3).contiguous()\n","        \n","        #x = [batch size, query len, n heads, head dim]\n","        \n","        x = x.view(batch_size, -1, self.hid_dim)\n","        \n","        #x = [batch size, query len, hid dim]\n","        \n","        x = self.fc_o(x)\n","        \n","        #x = [batch size, query len, hid dim]\n","        \n","        return x, attention"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gowPccJeGYn4"},"source":["### Position-wise Feedforward Layer"]},{"cell_type":"code","metadata":{"id":"3357DePAGYn4"},"source":["class PositionwiseFeedforwardLayer(nn.Module):\n","    def __init__(self, hid_dim, pf_dim, dropout):\n","        super().__init__()\n","        \n","        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n","        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, x):\n","        \n","        #x = [batch size, seq len, hid dim]\n","        \n","        x = self.dropout(torch.relu(self.fc_1(x)))\n","        \n","        #x = [batch size, seq len, pf dim]\n","        \n","        x = self.fc_2(x)\n","        \n","        #x = [batch size, seq len, hid dim]\n","        \n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lFsgDs9vGYn6"},"source":["### Decoder"]},{"cell_type":"code","metadata":{"id":"YDRYTpEgGYn6"},"source":["class Decoder(nn.Module):\n","    def __init__(self, \n","                 output_dim, \n","                 hid_dim, \n","                 n_layers, \n","                 n_heads, \n","                 pf_dim, \n","                 dropout, \n","                 device,\n","                 max_length = 100):\n","        super().__init__()\n","        \n","        self.device = device\n","        \n","        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n","        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n","        \n","        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n","                                                  n_heads, \n","                                                  pf_dim, \n","                                                  dropout, \n","                                                  device)\n","                                     for _ in range(n_layers)])\n","        \n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n","        \n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        \n","        #trg = [batch size, trg len]\n","        #enc_src = [batch size, src len, hid dim]\n","        #trg_mask = [batch size, trg len]\n","        #src_mask = [batch size, src len]\n","                \n","        batch_size = trg.shape[0]\n","        trg_len = trg.shape[1]\n","        \n","        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n","                            \n","        #pos = [batch size, trg len]\n","            \n","        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n","                \n","        #trg = [batch size, trg len, hid dim]\n","        \n","        for layer in self.layers:\n","            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        output = self.fc_out(trg)\n","        \n","        #output = [batch size, trg len, output dim]\n","            \n","        return output, attention"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tQJAYsSNGYn8"},"source":["### Decoder Layer"]},{"cell_type":"code","metadata":{"id":"-kC5d1d7GYn8"},"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, \n","                 hid_dim, \n","                 n_heads, \n","                 pf_dim, \n","                 dropout, \n","                 device):\n","        super().__init__()\n","        \n","        self.layer_norm = nn.LayerNorm(hid_dim)\n","        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device)\n","        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n","                                                                     pf_dim, \n","                                                                     dropout)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, trg, enc_src, trg_mask, src_mask):\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #enc_src = [batch size, src len, hid dim]\n","        #trg_mask = [batch size, trg len]\n","        #src_mask = [batch size, src len]\n","        \n","        #self attention\n","        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n","        \n","        #dropout, residual connection and layer norm\n","        trg = self.layer_norm(trg + self.dropout(_trg))\n","            \n","        #trg = [batch size, trg len, hid dim]\n","            \n","        #encoder attention\n","        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n","        \n","        #dropout, residual connection and layer norm\n","        trg = self.layer_norm(trg + self.dropout(_trg))\n","                    \n","        #trg = [batch size, trg len, hid dim]\n","        \n","        #positionwise feedforward\n","        _trg = self.positionwise_feedforward(trg)\n","        \n","        #dropout, residual and layer norm\n","        trg = self.layer_norm(trg + self.dropout(_trg))\n","        \n","        #trg = [batch size, trg len, hid dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        return trg, attention"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m_dhyjdLGYn9"},"source":["### Seq2Seq\n"]},{"cell_type":"code","metadata":{"id":"XuduyQhhGYn-"},"source":["class Seq2Seq(nn.Module):\n","    def __init__(self, \n","                 encoder, \n","                 decoder, \n","                 src_pad_idx, \n","                 trg_pad_idx, \n","                 device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_pad_idx = src_pad_idx\n","        self.trg_pad_idx = trg_pad_idx\n","        self.device = device\n","        \n","    def make_src_mask(self, src):\n","        \n","        #src = [batch size, src len]\n","        \n","        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n","\n","        #src_mask = [batch size, 1, 1, src len]\n","\n","        return src_mask\n","    \n","    def make_trg_mask(self, trg):\n","        \n","        #trg = [batch size, trg len]\n","        \n","        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n","        \n","        #trg_pad_mask = [batch size, 1, trg len, 1]\n","        \n","        trg_len = trg.shape[1]\n","        \n","        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n","        \n","        #trg_sub_mask = [trg len, trg len]\n","            \n","        trg_mask = trg_pad_mask & trg_sub_mask\n","        \n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        \n","        return trg_mask\n","\n","    def forward(self, src, s, trg):\n","        \n","        #src = [features, batch size, src len]\n","        #lmm = [batch size, src len]\n","        #trg = [batch size, trg len]\n","                \n","        src_mask = self.make_src_mask(src[0])\n","        trg_mask = self.make_trg_mask(trg)\n","        \n","        #src_mask = [batch size, 1, 1, src len]\n","        #trg_mask = [batch size, 1, trg len, trg len]\n","        \n","        enc_src = self.encoder(src, s, src_mask)\n","        \n","        #enc_src = [batch size, src len, hid dim]\n","                \n","        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n","        \n","        #output = [batch size, trg len, output dim]\n","        #attention = [batch size, n heads, trg len, src len]\n","        \n","        return output, attention"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eVshnEqrGYn_"},"source":["## Translation Model"]},{"cell_type":"code","metadata":{"id":"1vonjwgfSls-"},"source":["class TranslationModel():\n","    \"\"\"\n","    Example usage:\n","    model = TranslationModel(src_lens, SELECTED,len(fields[-1].vocab),\n","                                         SRC_PAD_IDX, TRG_PAD_IDX)\n","    \n","    print(model.count_parameters())\n","    model.optimize_parameters(train_iterator, valid_iterator, N_EPOCHS=15)\n","    model.model.load_state_dict(checkpoint['state_dict'])\n","    _, _, pred_trgs = model.translate_dataset(mt_test[1:], fields)\n","    \"\"\"\n","\n","    def __init__(self,\n","                 data_center,\n","                 HID_DIM = 256,\n","                 ENC_LAYERS = 3,\n","                 DEC_LAYERS = 3,\n","                 ENC_HEADS = 8,\n","                 DEC_HEADS = 8,\n","                 ENC_PF_DIM = 512,\n","                 DEC_PF_DIM = 512,\n","                 ENC_DROPOUT = 0.1,\n","                 DEC_DROPOUT = 0.1,\n","                 device = 'cuda'):\n","        \n","        #self.name = f\"{data_center.name}.{int(time.time())}.model\"\n","        self.name = f\"{data_center.name}.model\"\n","        \n","        self.device = device\n","\n","        self.TRG_PAD_IDX = data_center.TRG_PAD_IDX\n","        self.SELECTED = data_center.SELECTED\n","        enc = Encoder(data_center.src_lens, data_center.SELECTED,\n","                HID_DIM, \n","                ENC_LAYERS, \n","                ENC_HEADS, \n","                ENC_PF_DIM, \n","                ENC_DROPOUT, \n","                device)\n","\n","        dec = Decoder(data_center.trg_len, \n","                    HID_DIM, \n","                    DEC_LAYERS, \n","                    DEC_HEADS, \n","                    DEC_PF_DIM, \n","                    DEC_DROPOUT, \n","                    device)\n","        self.model = Seq2Seq(enc, dec, data_center.SRC_PAD_IDX, data_center.TRG_PAD_IDX, device).to(device)\n","\n","        self.data_center = data_center\n","\n","    \n","    def load_model(self, model_name=None):\n","        #Loading the best model\n","        if not model_name:\n","            checkpoint = torch.load(f'{self.name}.pt')\n","        else:\n","            checkpoint = torch.load(model_name)\n","        self.model.load_state_dict(checkpoint['state_dict'])\n","    \n","    \n","    # check the number of parameters\n","    def count_parameters(self):\n","        return sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n","    \n","\n","    def optimize_parameters(self, N_EPOCHS=20):\n","        \n","        train_iterator, valid_iterator = self.data_center.train_iterator, self.data_center.valid_iterator\n","        \n","        TRG_PAD_IDX = self.TRG_PAD_IDX\n","        model = self.model\n","        s = self.SELECTED\n","        def train_an_epoch(model, s, iterator, optimizer, criterion, clip):\n","        \n","            model.train()\n","            \n","            epoch_loss = 0\n","            \n","            for i, batch in enumerate(iterator):\n","\n","                batch_dict = vars(batch)\n","\n","                src = [batch_dict[feature] for feature in list(batch.fields)[:-1]]\n","\n","                # if not(len(src[0][0])==len(src[1][0])==len(src[2][0])==len(src[3][0])==len(src[4][0])==len(src[5][0])==len(src[6][0])==len(src[7][0])):\n","                #     print(batch.ru) \n","                \n","                trg = batch.vi\n","                \n","                optimizer.zero_grad()\n","                \n","                output, _ = model(src, s, trg[:,:-1])\n","                        \n","                #output = [batch size, trg len - 1, output dim]\n","                #trg = [batch size, trg len]\n","                    \n","                output_dim = output.shape[-1]\n","                    \n","                output = output.contiguous().view(-1, output_dim)\n","                trg = trg[:,1:].contiguous().view(-1)\n","                        \n","                #output = [batch size * trg len - 1, output dim]\n","                #trg = [batch size * trg len - 1]\n","                    \n","                loss = criterion(output, trg)\n","                \n","                loss.backward()\n","                \n","                torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","                \n","                optimizer.step()\n","                \n","                epoch_loss += loss.item()\n","                \n","            return epoch_loss / len(iterator)\n","        \n","        \n","        def evaluate_an_epoch(model, s, iterator, criterion):\n","            \n","            model.eval()\n","            \n","            epoch_loss = 0\n","            \n","            with torch.no_grad():\n","            \n","                for i, batch in enumerate(iterator):\n","\n","                    batch_dict = vars(batch)\n","\n","                    src = [batch_dict[feature] for feature in list(batch.fields)[:-1]]\n","                    trg = batch.vi\n","\n","                    output, _ = model(src, s, trg[:,:-1])\n","                    \n","                    #output = [batch size, trg len - 1, output dim]\n","                    #trg = [batch size, trg len]\n","                    \n","                    output_dim = output.shape[-1]\n","                    \n","                    output = output.contiguous().view(-1, output_dim)\n","                    trg = trg[:,1:].contiguous().view(-1)\n","                    \n","                    #output = [batch size * trg len - 1, output dim]\n","                    #trg = [batch size * trg len - 1]\n","                    \n","                    loss = criterion(output, trg)\n","\n","                    epoch_loss += loss.item()\n","                \n","            return epoch_loss / len(iterator)\n","        \n","\n","        #Xavier uniform seems to be common amongst Transformer models, so we use it here\n","        def initialize_weights(m):\n","            if hasattr(m, 'weight') and m.weight.dim() > 1:\n","                nn.init.xavier_uniform_(m.weight.data)\n","        \n","        \n","        model.apply(initialize_weights);\n","        # Note that the learning rate needs to be lower than the default used by Adam or else learning is unstable.\n","        LEARNING_RATE = 0.0005\n","\n","        optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n","        # Next, we define our loss function, making sure to ignore losses calculated over `<pad>` tokens.\n","        criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n","\n","        '''\n","        Finally, we train our actual model. This model is almost 3x faster than the \n","        convolutional sequence-to-sequence model and also achieves \n","        a lower validation perplexity!\n","        '''\n","        CLIP = 1\n","        epoch = 0\n","\n","        best_valid_loss = float('inf')\n","\n","        while epoch < N_EPOCHS:\n","            # print(\"Training %s-th epoch\" % epoch)\n","            \n","            start_time = time.time()\n","            \n","            train_loss = train_an_epoch(model, s, train_iterator, optimizer, criterion, CLIP)\n","            valid_loss = evaluate_an_epoch(model, s, valid_iterator, criterion)\n","            \n","            end_time = time.time()\n","            \n","            epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","            \n","            if valid_loss < best_valid_loss:\n","                best_valid_loss = valid_loss\n","                best_epoch = epoch\n","\n","                checkpoint = {'epoch': epoch, 'state_dict': model.state_dict()}\n","        \n","                torch.save(checkpoint, f'{self.name}.pt')\n","            \n","            # print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","            # print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","            # print(f'\\t Val. Loss: {valid_loss} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","\n","            epoch += 1\n","\n","        print(f'The best number of epochs for training model: ', best_epoch + 1)\n","\n","    \n","    def translate_sentence(self, factor_sentences, fields, max_len = 50):\n","        \n","        s = self.SELECTED\n","        model = self.model\n","        device = self.device\n","\n","        model.eval()\n","        \n","        factor_tokens_sequences = [[fields[i].init_token] + tokens + [fields[i].eos_token] \n","                                for i, tokens in enumerate(factor_sentences)]\n","            \n","        factor_indices_sequences = [[fields[i].vocab.stoi[token] for token in tokens] \n","                                    for i, tokens in enumerate(factor_tokens_sequences)]\n","        \n","\n","        src_tensors = [torch.LongTensor(src_indices).unsqueeze(0).to(device) for src_indices in factor_indices_sequences]\n","        \n","        src_mask = model.make_src_mask(src_tensors[0])\n","        \n","        with torch.no_grad():\n","            enc_src = model.encoder(src_tensors, s, src_mask)\n","\n","        trg_field = fields[-1]\n","        trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","\n","        for i in range(max_len):\n","\n","            trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","\n","            trg_mask = model.make_trg_mask(trg_tensor)\n","            \n","            with torch.no_grad():\n","                output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n","            \n","            pred_token = output.argmax(2)[:,-1].item()\n","            \n","            trg_indexes.append(pred_token)\n","\n","            if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","                break\n","        \n","        trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","        \n","        return trg_tokens[1:], attention    \n","    \n","    #Finally we calculate the BLEU score for the Transformer.\n","    def translate_dataset(self, max_len=100):\n","\n","        data = self.data_center.mt_test\n","        fields = self.data_center.field_sequence\n","        s = self.SELECTED\n","        model = self.model\n","        device = self.device\n","\n","        srcs = []\n","        trgs = []\n","        pred_trgs = []\n","        \n","        for i, datum in enumerate(data):\n","            \n","            dat_dict = vars(datum) # a dict of feature - feature_senquence\n","            src = [dat_dict[feature] for feature in  list(dat_dict.keys())[:-1]]\n","            trg = dat_dict['vi']\n","                \n","            \n","            pred_trg, _ = self.translate_sentence(src, fields, max_len)\n","            \n","            #cut off <eos> token\n","            pred_trg = pred_trg[:-1]\n","            \n","            pred_trgs.append(pred_trg)\n","            trgs.append([trg])\n","            srcs.append([src])\n","            \n","        return srcs, trgs, pred_trgs\n","    \n","    def translate_sentence_beam_search(self, factor_sentences, fields, max_len = 50):\n","        \n","        beam_width = 5\n","        m = nn.Softmax(dim=2)\n","        s = self.SELECTED\n","        model = self.model\n","        device = self.device\n","\n","        model.eval()\n","        \n","        factor_tokens_sequences = [[fields[i].init_token] + tokens + [fields[i].eos_token] \n","                                for i, tokens in enumerate(factor_sentences)]\n","            \n","        factor_indices_sequences = [[fields[i].vocab.stoi[token] for token in tokens] \n","                                    for i, tokens in enumerate(factor_tokens_sequences)]\n","        \n","\n","        src_tensors = [torch.LongTensor(src_indices).unsqueeze(0).to(device) for src_indices in factor_indices_sequences]\n","        \n","        src_mask = model.make_src_mask(src_tensors[0])\n","        \n","        with torch.no_grad():\n","            enc_src = model.encoder(src_tensors, s, src_mask)\n","\n","        trg_field = fields[-1]\n","        trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","        logprob = 0\n","        trg_indexes_list = [(trg_indexes, logprob)]\n","\n","        for i in range(max_len):\n","\n","            trg_indexes_newlist = []\n","            for trg_indexes, logprob in trg_indexes_list:\n","\n","                if trg_indexes[-1] != trg_field.vocab.stoi[trg_field.eos_token]:\n","\n","                    trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n","\n","                    trg_mask = model.make_trg_mask(trg_tensor)\n","                    \n","                    with torch.no_grad():\n","                        output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n","                \n","                    #pred_token = output.argmax(2)[:,-1].item()\n","                    output = m(output)\n","                    pred_probs, pred_tokens = output.topk(beam_width)\n","                    #pred_probs, pred_tokens = pred_probs.cpu().detach().numpy(), pred_tokens.cpu().detach().numpy()\n","                    #print(pred_probs, pred_tokens)\n","                    for i in range(beam_width):\n","                        temp = copy.deepcopy(trg_indexes)\n","                        temp.append(pred_tokens[0][-1][i])\n","                        trg_indexes_newlist.append((temp,logprob - torch.log(pred_probs[0][-1][i])))\n","            \n","            #print(trg_indexes_newlist)\n","            trg_indexes_newlist = sorted(trg_indexes_newlist, key=lambda x: x[1] / float(len(x[0]) - 1 + 1e-6))\n","            trg_indexes_newlist = trg_indexes_newlist[:beam_width]\n","            trg_indexes_list = copy.deepcopy(trg_indexes_newlist)\n","            #print(trg_indexes_list)\n","\n","            if trg_indexes_list[0][0][-1] == trg_field.vocab.stoi[trg_field.eos_token]:\n","                break\n","        \n","        trg_indexes, _ = trg_indexes_list[0]\n","\n","        trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","        #print(trg_tokens)\n","        \n","        return trg_tokens[1:], attention    \n","    \n","    \n","    #Finally we calculate the BLEU score for the Transformer.\n","    def translate_dataset_beam_search(self, max_len=100):\n","\n","        data = self.data_center.mt_test\n","        fields = self.data_center.field_sequence\n","        s = self.SELECTED\n","        model = self.model\n","        device = self.device\n","\n","        srcs = []\n","        trgs = []\n","        pred_trgs = []\n","        \n","        for i, datum in enumerate(data):\n","\n","            print(i)\n","            \n","            dat_dict = vars(datum) # a dict of feature - feature_senquence\n","            src = [dat_dict[feature] for feature in  list(dat_dict.keys())[:-1]]\n","            trg = dat_dict['vi']\n","                \n","            \n","            pred_trg, _ = self.translate_sentence_beam_search(src, fields, max_len)\n","            \n","            #cut off <eos> token\n","            pred_trg = pred_trg[:-1]\n","            \n","            pred_trgs.append(pred_trg)\n","            trgs.append([trg])\n","            srcs.append([src])\n","            print(pred_trg)\n","            \n","        return srcs, trgs, pred_trgs\n","\n","# We then define a small function that we can use to tell us how long an epoch takes.\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs   "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"afI1gqKtRo2R"},"source":["# RUN"]},{"cell_type":"markdown","metadata":{"id":"HE0Rhp_uiK-8"},"source":["*Remember executing \"Run Before\"*"]},{"cell_type":"markdown","metadata":{"id":"JwZZuLVJh3C6"},"source":["##Prepare"]},{"cell_type":"code","metadata":{"id":"ED9pwR0mq-Be","executionInfo":{"status":"ok","timestamp":1604216340036,"user_tz":-420,"elapsed":5353,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}}},"source":["import nltk\n","import copy\n","import os\n","import subprocess\n","import re\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchtext\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","import spacy\n","import numpy as np\n","import pandas as pd\n","import random\n","import math\n","import time\n","import itertools\n","from nltk.translate.bleu_score import sentence_bleu\n","from nltk.translate.bleu_score import corpus_bleu\n","from shutil import copyfile\n","from torchtext.data import Field, BucketIterator, TabularDataset\n","from  torchtext import data\n","from collections import defaultdict\n","from datetime import datetime"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"UbSiflkx5Jwp","executionInfo":{"status":"ok","timestamp":1604216385823,"user_tz":-420,"elapsed":25681,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"8f25d969-87af-49de-d13d-b7eefc57b66b","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yvrryI5JDvp9","executionInfo":{"status":"ok","timestamp":1604216391983,"user_tz":-420,"elapsed":924,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}}},"source":["#Choosing path to workspace\n","path = '/content/gdrive/My Drive/nmt_models/MPinE_8_2020'\n","if not os.path.exists(path):\n","    os.mkdir(path)\n","os.chdir(path)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"JzRxzkP6o1aF","executionInfo":{"status":"ok","timestamp":1594183045527,"user_tz":-420,"elapsed":15856,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"dac86ca3-b8a5-42a6-eca2-255a64232add","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(datetime.now().strftime(\"%H:%M:%S\"))\n","#ru_token_type = word => select is of size 8 ['ru', le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'translation']\n","#ru_token_type = unigram/bpe => select is of size 9 ['ru', 'subtag', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'translation']\n","#['ru', 'subtag', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'translation']\n","select = [0, 1, 0, 0, 1, 1, 1, 0]\n","data_center = DataCenter(ru_token_type='word', vi_token_type='word', SELECTED = np.array(select))\n","print(datetime.now().strftime(\"%H:%M:%S\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["04:37:13\n","04:37:24\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d-gIOIiKpe2Y"},"source":["##Train"]},{"cell_type":"code","metadata":{"id":"9iIbuAXWleBw"},"source":["print(datetime.now().strftime(\"%H:%M:%S\"))\n","model = TranslationModel(data_center, HID_DIM=256, device=device)\n","print(datetime.now().strftime(\"%H:%M:%S\"))\n","print(f'The model has {model.count_parameters():,} trainable parameters')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tq_A8xHuRnpR","executionInfo":{"status":"ok","timestamp":1594183858145,"user_tz":-420,"elapsed":828426,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"39e9febd-a902-408e-ec4e-8df833168874","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["print(datetime.now().strftime(\"%H:%M:%S\"))\n","model.optimize_parameters(N_EPOCHS=20)\n","print(datetime.now().strftime(\"%H:%M:%S\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["04:37:24\n","The model has 9,281,394 trainable parameters\n","The best number of epochs for training model:  14\n","04:50:57\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6z4WaHuZoOVA"},"source":["##Test"]},{"cell_type":"code","metadata":{"id":"e8buXTP0F7y8","executionInfo":{"status":"ok","timestamp":1594184066366,"user_tz":-420,"elapsed":1036603,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"8700bc11-e38c-4a2d-c60e-e5fab124f1ec","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print(datetime.now().strftime(\"%H:%M:%S\"))\n","\n","# mt_dev shares the fields, so it shares their vocab objects\n","\n","#model = TranslationModel(data_center, HID_DIM=256, device=device)\n","\n","model.load_model()\n","#model.load_model(f\"{model_name}.pt\")\n","# translate_dataset(self, data, fields, max_len=25)\n","#print(datetime.now().strftime(\"%H:%M:%S\"))\n","#srcs, trgs, pred_trgs = model.translate_dataset_beam_search(max_len=100)\n","srcs, trgs, pred_trgs = model.translate_dataset(max_len=100)\n","print(datetime.now().strftime(\"%H:%M:%S\"))\n","\n","\n","def save2file(s, filename):\n","    with open(filename, 'w') as file:\n","        for line in s:\n","            l = ' '.join(line) + '\\n'\n","            file.write(l)\n","\n","#Subword.join_pieces(pred_trgs, f'pred_{model.name}.vi', type='bpe')\n","save2file(pred_trgs, f'pred_{model.name}.vi')\n","DataCenter.detokenize(f'pred_{model.name}.vi', f'__pred_{model.name}.vi')\n","\n","#save2file(pred_trgs, f'pred_{model_name}.log.beam.vi')\n","#DataCenter.detokenize(f'pred_{model_name}.log.beam.vi', f'__pred_{model_name}.log.beam.vi')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["04:50:57\n","04:54:25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m6p65gq2qVw9"},"source":["##Evaluate"]},{"cell_type":"code","metadata":{"id":"3ao08K_THEzZ"},"source":["ru = open('test.ru', 'r').read().splitlines()\n","vi = open('test.vi', 'r').read().splitlines()\n","w2w = open('W2W.model.vi', 'r').read().splitlines()\n","w2w_sb = open('W2W.sb', 'r').read().splitlines()\n","s2s = open('S2S.model.vi', 'r').read().splitlines()\n","s2s_sb = open('S2S.sb', 'r').read().splitlines()\n","snf2s = open('SnF2S.model.vi', 'r').read().splitlines()\n","snf2s_sb = open('SnF2S.sb', 'r').read().splitlines()\n","f2w = open('F2W.model.vi', 'r').read().splitlines()\n","f2w_sb = open('F2W.sb', 'r').read().splitlines()\n","all = open('all.all', 'w')\n","for i in zip(ru, vi, w2w, w2w_sb, s2s, s2s_sb, snf2s, snf2s_sb, f2w, f2w_sb):\n","    all.write('\\n'.join(i) + '\\n')\n","all.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yyZ2pQAduweP","executionInfo":{"status":"ok","timestamp":1604216706758,"user_tz":-420,"elapsed":882,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}}},"source":["#filter sentences where SnF2S is better than F2W and Russian sentences have length from 10 to 13\n","ru = open('test.ru', 'r').read().splitlines()\n","vi = open('test.vi', 'r').read().splitlines()\n","w2w = open('W2W.model.vi', 'r').read().splitlines()\n","w2w_sb = open('W2W.sb', 'r').read().splitlines()\n","s2s = open('S2S.model.vi', 'r').read().splitlines()\n","s2s_sb = open('S2S.sb', 'r').read().splitlines()\n","snf2s = open('SnF2S.model.vi', 'r').read().splitlines()\n","snf2s_sb = open('SnF2S.sb', 'r').read().splitlines()\n","f2w = open('F2W.model.vi', 'r').read().splitlines()\n","f2w_sb = open('F2W.sb', 'r').read().splitlines()\n","all = open('filter.all', 'w')\n","for i in zip(ru, vi, w2w, w2w_sb, s2s, s2s_sb, snf2s, snf2s_sb, f2w, f2w_sb):\n","    if (float(i[-7]) < float(i[-5])) and (float(i[-5]) < float(i[-3])) and (float(i[-3]) > float(i[-1])) and (len(i[0].split(' ')) <= 13):\n","        all.write('\\n'.join(i) + '\\n')\n","all.close()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"FgeZFAn5KXE2","executionInfo":{"status":"ok","timestamp":1604216710288,"user_tz":-420,"elapsed":967,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"09e779a9-f532-49a8-b122-38e58dadaf1a","colab":{"base_uri":"https://localhost:8080/"}},"source":["!head filter.all"],"execution_count":7,"outputs":[{"output_type":"stream","text":["кризисы доверия порождают угрозу возникновения аналогичных кризисов в будущем .\n","khủng hoảng niềm tin tạo ra mối đe doạ của các cuộc khủng hoảng tương tự trong tương lai . \n","các cuộc khủng hoảng niềm tin của các cuộc khủng hoảng tương tự đã xảy ra trong tương lai . \n","0.484331687499726\n","các cuộc khủng hoảng niềm tin đe doạ gây ra mối đe doạ tương tự trong tương lai của các cuộc khủng hoảng . \n","0.5758522372341492\n","cuộc khủng hoảng niềm tin tạo ra một mối đe doạ cho các cuộc khủng hoảng tương tự trong tương lai . \n","0.7045307573858761\n","các cuộc khủng hoảng niềm tin làm nảy sinh một mối đe doạ của các cuộc khủng hoảng tương tự trong tương lai . \n","0.6748913185157768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0OvXY0IwxdPi"},"source":["#vi_data = pd.read_csv('new.vi.tsv', sep='\\t')['syllable']\n","#vi_data.iloc[:1500].to_csv('__test.vi', sep='\\t', index=False, header=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sHv7DU-FyDdL"},"source":["def evaluate_bleu_nltk(reference_filename, hypothesis_filename):\n","    references = open(reference_filename).read().splitlines()\n","    references = [line.split(' ') for line in references]\n","    hypotheses = open(hypothesis_filename, 'r').read().splitlines()\n","    hypotheses = [line.split(' ') for line in hypotheses]\n","\n","    bleus = [sentence_bleu([r], h) for r, h in zip(references, hypotheses)]\n","\n","    list_refs = [[r] for r in references]\n","\n","    return bleus, corpus_bleu(list_refs, hypotheses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MAETB8iNHlQx"},"source":["cb = evaluate_bleu_nltk(reference_filename='__test.vi', \n","                        hypothesis_filename=f'__pred_{model.name}.vi')\n","#cb = evaluate_bleu_nltk(reference_filename='__test-4.vi', \n","#                        hypothesis_filename=f'pred_{model_name}.log.beam.vi')\n","print(cb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lO2pkgGLHpDc","executionInfo":{"status":"ok","timestamp":1595582534666,"user_tz":-420,"elapsed":3181,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"4d909c90-9015-45c3-fecb-11c1747d3e71","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["cb = evaluate_bleu_nltk(reference_filename='__test.vi', \n","                        hypothesis_filename='pred_word1000000word.model0.vi')\n","print(cb)\n","\n","cb = evaluate_bleu_nltk(reference_filename='__test.vi', \n","                        hypothesis_filename='pred_bpe10000000bpe.model0.vi')\n","print(cb)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.3444753188424447\n","0.3698674546165114\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"165UJeledTws","executionInfo":{"status":"ok","timestamp":1603885776736,"user_tz":-420,"elapsed":5759,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"d2155ad8-323a-4635-ee11-e736e66be9b2","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["s1, c1 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='F2W.model.vi')\n","print(c1)\n","s1f = open('F2W.sb', 'w')\n","s1f.write('\\n'.join(map(str, s1)))\n","\n","s2, c2 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='SnF2S.model.vi')\n","print(c2)\n","s2f = open('SnF2S.sb', 'w')\n","s2f.write('\\n'.join(map(str, s2)))\n","s1f.close()\n","s2f.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["0.45566451634195343\n","0.40819892374214767\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["28801"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"ycqaaA6fQAqS","executionInfo":{"status":"ok","timestamp":1604057072842,"user_tz":-420,"elapsed":3922,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"f2ddf861-87b7-4def-96fd-efc37bcfcc7f","colab":{"base_uri":"https://localhost:8080/"}},"source":["s1, c1 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='Copy of pred_word1000000word.model0.vi')\n","print(c1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["0.3444753188424447\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SbAY9wDNQa6v","executionInfo":{"status":"ok","timestamp":1604057175418,"user_tz":-420,"elapsed":2367,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"e04e894c-4040-4fae-e04e-6175cb0c6d92","colab":{"base_uri":"https://localhost:8080/"}},"source":["s1, c1 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='Copy of pred_bpe10000000bpe.model0.vi')\n","print(c1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["0.3698674546165114\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hbvoATKZoDp9","executionInfo":{"status":"ok","timestamp":1604030129792,"user_tz":-420,"elapsed":2136,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"16de45c4-5049-49d4-8a6a-50867179c1e7","colab":{"base_uri":"https://localhost:8080/"}},"source":["s1, c1 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='W2W.model.vi')\n","print(c1)\n","s1f = open('W2W.sb', 'w')\n","s1f.write('\\n'.join(map(str, s1)))\n","\n","s2, c2 = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='S2S.model.vi')\n","print(c2)\n","s2f = open('S2S.sb', 'w')\n","s2f.write('\\n'.join(map(str, s2)))\n","s1f.close()\n","s2f.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["0.337865649065229\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"stream","text":["0.3677826479020239\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wx7btARJULMQ"},"source":["s1f = np.array(list(map(float, open('F2W.sb', 'r').read().splitlines())))\n","s2f = np.array(list(map(float, open('SnF2S.sb', 'r').read().splitlines())))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMNngQSRVj2Z","executionInfo":{"status":"ok","timestamp":1603991420793,"user_tz":-420,"elapsed":1190,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"65155a86-f0aa-4b0d-e97e-2c9668e6e1f6","colab":{"base_uri":"https://localhost:8080/"}},"source":["s1f"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.21279883, 0.88438659, 0.36736666, ..., 0.44794052, 0.38096949,\n","       0.63206862])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"bSEUxT1HUirf"},"source":["import pylab"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BgTjjkulUohD","executionInfo":{"status":"ok","timestamp":1603992386626,"user_tz":-420,"elapsed":1824,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"69b9aa21-d6b8-440c-b724-b3f1096c7879","colab":{"base_uri":"https://localhost:8080/","height":401}},"source":["pylab.hist(-s1f+s2f, bins = 20)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([  2.,   1.,   1.,   4.,  14.,  16.,  58.,  86., 130., 182., 250.,\n","        295., 204., 116.,  63.,  39.,  23.,  10.,   3.,   3.]),\n"," array([-0.75484765, -0.68858095, -0.62231425, -0.55604755, -0.48978086,\n","        -0.42351416, -0.35724746, -0.29098076, -0.22471407, -0.15844737,\n","        -0.09218067, -0.02591397,  0.04035272,  0.10661942,  0.17288612,\n","         0.23915282,  0.30541951,  0.37168621,  0.43795291,  0.50421961,\n","         0.57048631]),\n"," <a list of 20 Patch objects>)"]},"metadata":{"tags":[]},"execution_count":21},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"dhaBSjd3XOQk","executionInfo":{"status":"ok","timestamp":1603991860592,"user_tz":-420,"elapsed":958,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"cca4eb91-fb0f-441d-e9f0-95f5132465cf","colab":{"base_uri":"https://localhost:8080/"}},"source":["np.sum(s1f-s2f)/1500"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.03246123617266937"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"17cb9StdqPLd","executionInfo":{"status":"ok","timestamp":1603863071724,"user_tz":-420,"elapsed":957,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"131d4e76-1393-4e10-c283-cb24ed2339c8","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["ns1 = np.array(s1)\n","ns2 = np.array(s2)\n","xxx = np.sum(ns1 > ns2)\n","print(xxx)\n","yyy = np.sum(ns1 < ns2)\n","print(yyy)\n","zzz = np.sum(ns1 == ns2)\n","print(zzz)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["864\n","617\n","19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_R0hWqIBk8Rz","executionInfo":{"status":"ok","timestamp":1603794118801,"user_tz":-420,"elapsed":1065,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"f95129a9-92ca-472f-ea08-bb14f9622847","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(s1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1500"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"GYV0BtXklFJz","executionInfo":{"status":"error","timestamp":1603794137935,"user_tz":-420,"elapsed":1022,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"4892f64e-a9b7-4816-8fdf-ce08fe432af3","colab":{"base_uri":"https://localhost:8080/","height":163}},"source":["sum"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d3896d02c6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'mean' is not defined"]}]},{"cell_type":"code","metadata":{"id":"bkpKQRjKiQAn","executionInfo":{"status":"ok","timestamp":1603793648751,"user_tz":-420,"elapsed":1751,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"5e34467d-54b3-42f2-a35a-5134e91fb783","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["x = [1,2,3]\n","print('\\n'.join(map(str, x)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"H4OIfI7LRki4"},"source":["0.35760860600116273\n","\n","0.3508676914905399 (beam 0)\n","\n","0.36784570422204343 (beam 1)\n","\n","0.445131941036839 (smt)\n","\n","word2word 0.337865649065229 (nen dung ket qua cu cho thong nhat)\n","\n","bpe2bpe 0.3677826479020239 (nen dung ket qua cu cho thong nhat)\n","\n","bpe2bpe all features 0.40819892374214767\n","\n","bpe2bpe decomposing 0.44710190616016554\n","\n","word2word decomposing 0.45646605637728693\n","\n"]},{"cell_type":"code","metadata":{"id":"nkEE51OlixNQ","executionInfo":{"status":"ok","timestamp":1594184066368,"user_tz":-420,"elapsed":1036511,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"08c3178d-4171-4298-ce53-61e615ff01ab","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print(f'{model.name}  {cb}') #word01001110word.model  0.4588935187948537 0.45646605637728693"],"execution_count":null,"outputs":[{"output_type":"stream","text":["word01001110word.model  0.45646605637728693\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q-VygQ0UeMsz"},"source":["!head pred_word10000001word.add.model.vi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"81Bda-Ehx7Wz"},"source":["**ru_word5input_features, vi_word**\n","\n","BLEU scores 0.3904458228518665\n","\n","**ru_word 4without_source, vi_word**\n","\n","BLEU scores 0.4189770753461321\n","\n","**subword_all6input_features**\n","\n","BLEU scores 0.38121640766613113\n","\n","**ru:word with all features, vi: word**\n","\n","BLEU scores 0.3898409604570488\n","\n","**ru:word with all features, vi: syllable**\n","\n","BLEU scores 0.38041187275465776\n","\n","**pred_ru_bpe_with_all_features_vi_unigram**\n","\n","BLEU scores 0.3585956366346239\n","\n","**pred_ru_unigram_with_all_features_vi_unigram**\n","\n","BLEU scores 0.37430989535380627"]},{"cell_type":"markdown","metadata":{"id":"bhGaL033feg1"},"source":["##Subword"]},{"cell_type":"code","metadata":{"id":"izxWcq5FyWtl"},"source":["import sentencepiece as spm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yezIMN22HsSQ"},"source":["ru_subword = Subword('ru', 4000)\n","ru_subword.split_words('train.ru', 'train.unigram.ru')\n","ru_subword.split_words('dev.ru', 'dev.unigram.ru')\n","ru_subword.split_words('test.ru', 'test.unigram.ru')\n","\n","vi_subword = Subword('vi', 2000)\n","vi_subword.split_words('train.vi', 'train.unigram.vi')\n","vi_subword.split_words('dev.vi', 'dev.unigram.vi')\n","vi_subword.split_words('test.vi', 'test.unigram.vi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2bU2vF4FF_j","executionInfo":{"status":"ok","timestamp":1588727271479,"user_tz":-420,"elapsed":6688,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"cf77928c-4f0b-4650-d1ee-b2cc6ce5626c","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["!pip install sentencepiece"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\r\u001b[K     |▎                               | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 10.4MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 8.6MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.86\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bDhyoy3amMrs","executionInfo":{"status":"ok","timestamp":1588729903088,"user_tz":-420,"elapsed":7837,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"00275ff0-938a-4949-b1d1-2f8752b84661","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["!pip install subword-nmt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting subword-nmt\n","  Downloading https://files.pythonhosted.org/packages/74/60/6600a7bc09e7ab38bc53a48a20d8cae49b837f93f5842a41fe513a694912/subword_nmt-0.3.7-py2.py3-none-any.whl\n","Installing collected packages: subword-nmt\n","Successfully installed subword-nmt-0.3.7\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pXZLoeSFmTKl"},"source":["test_ru_data = pd.read_csv('test.tsv', sep='\\t')['ru'].to_list()\n","dev_ru_data = pd.read_csv('dev.tsv', sep='\\t')['ru'].to_list()\n","train_ru_data = pd.read_csv('train.tsv', sep='\\t')['ru'].to_list()\n","\n","test_vi_data = pd.read_csv('test.tsv', sep='\\t')['vi'].to_list()\n","dev_vi_data = pd.read_csv('dev.tsv', sep='\\t')['vi'].to_list()\n","train_vi_data = pd.read_csv('train.tsv', sep='\\t')['vi'].to_list()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-DmzAyrKm4Kr","executionInfo":{"status":"ok","timestamp":1588667492875,"user_tz":-420,"elapsed":1962,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"b191a11b-1da0-4164-96d4-53334c63244a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["open('test.ru', 'w').write('\\n'.join(test_ru_data))\n","open('dev.ru', 'w').write('\\n'.join(dev_ru_data))\n","open('train.ru', 'w').write('\\n'.join(train_ru_data))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2957774"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"qq794kMCBz6m","executionInfo":{"status":"ok","timestamp":1588668627968,"user_tz":-420,"elapsed":877,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"6b608c54-07df-41f4-d41a-5f22ce26e199","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["open('__test.vi', 'w').write('\\n'.join(test_vi_data))\n","open('__dev.vi', 'w').write('\\n'.join(dev_vi_data))\n","open('__train.vi', 'w').write('\\n'.join(train_vi_data))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2957774"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"oP0j2l4TBeWw"},"source":["detokenize('__test.vi', 'test.vi')\n","detokenize('__dev.vi', 'dev.vi')\n","detokenize('__train.vi', 'train.vi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f__DJvxDnacx","executionInfo":{"status":"ok","timestamp":1588667624447,"user_tz":-420,"elapsed":24660,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"725cafbd-afe4-42b9-f0a7-51e1b2a1754a","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["%%shell\n","subword-nmt learn-bpe -s 10000 < train.ru > ru.bpe"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"rJjzgcrCA2Yy"},"source":["!subword-nmt learn-bpe -s 1500 < train.vi > vi.bpe"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N6rXcaEvobcS","executionInfo":{"status":"ok","timestamp":1588667782242,"user_tz":-420,"elapsed":6709,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"e9bf4317-31a2-4e08-b63c-f333dbc80bee","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["%%shell\n","subword-nmt apply-bpe -c ru.bpe < test.ru > test.bpe.ru\n","subword-nmt apply-bpe -c ru.bpe < dev.ru > dev.bpe.ru\n","subword-nmt apply-bpe -c ru.bpe < train.ru > train.bpe.ru"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"2Dgr9sci-qmS","executionInfo":{"status":"ok","timestamp":1588669067783,"user_tz":-420,"elapsed":3628,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"57fcc061-99a0-43e2-dd81-a4070da20a96","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["%%shell\n","subword-nmt apply-bpe -c vi.bpe < test.vi > test.bpe.vi\n","subword-nmt apply-bpe -c vi.bpe < dev.vi > dev.bpe.vi\n","subword-nmt apply-bpe -c vi.bpe < train.vi > train.bpe.vi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"uBMI3lDer3hU"},"source":["!subword-nmt apply-bpe -c vi.bpe < test.vi > test.bpe.vi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXCkyc8I-2RS","executionInfo":{"status":"ok","timestamp":1589032950983,"user_tz":-420,"elapsed":6065,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"1d15a024-eb94-49b1-bdca-42dafd279a7a","colab":{"base_uri":"https://localhost:8080/","height":207}},"source":["!head test.bpe.vi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["thiên tài của i@@ o@@ n@@ es@@ c@@ o là khả năng mô tả một thế giới trong đó điều phi lý chiến thắng . \n","tất cả đều kêu gọi hành động chính trị chung , ng@@ ụ ý sự cần thiết phải đàm phán với t@@ al@@ i@@ ban . \n","phản ứng trước sự gây h@@ ấn ban đầu của h@@ e@@ z@@ bo@@ l@@ la@@ h , cũng như hành động quân sự trả đ@@ ũ@@ a của israel ở gaza , rất khắc ngh@@ iệt . \n","cùng với các trường hợp tương tự khác , các vụ kiện này đặt ra những câu hỏi nghiêm trọng về hệ thống tư pháp của ukraine và các cơ quan thực thi pháp luật . \n","không có nghi ngờ rằng d@@ a@@ ch đã vi phạm quyền của hàng ng@@ àn người kh@@ me@@ r . \n","để trở về mức độ việc làm trước khi suy thoái kinh tế mỹ , cần hơn 11 triệu việc làm mới . \n","nhưng trong trường hợp này , chúng tôi đã quá b@@ ận tâm với tình hình hiện tại đến nỗi chúng tôi đã vượt qua mọi khác biệt . \n","sau chiến thắng của al@@ l@@ en@@ de , thị trường chứng khoán và thị trường ch@@ il@@ e đã bị k@@ ìm hã@@ m bởi sự hoảng loạn tài chính . \n","nếu bạn không nhìn thấy phẩm chất con người trong đối thủ của mình , bạn sẽ không nói chuyện với anh ta . \n","và họ muốn có một câu trả lời cho câu hỏi về số phận của hàng trăm người bị coi là mất tích đã mười năm . \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fnkq-XcUxRYk","executionInfo":{"status":"ok","timestamp":1589033409239,"user_tz":-420,"elapsed":1214,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"dd46c73f-03a7-4bd0-a6a0-4cec734d7c4c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["testsent = 'thiên tài của i@@ o@@ n@@ es@@ c@@ o là khả năng mô tả một thế giới trong đó điều phi lý chiến thắng .'\n","testsent.replace('@@ ','')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'thiên tài của ionesco là khả năng mô tả một thế giới trong đó điều phi lý chiến thắng .'"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"3DPJF6WSvwUu","executionInfo":{"status":"ok","timestamp":1589033223995,"user_tz":-420,"elapsed":1237,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"bfa16dac-0221-40a7-acbf-3bf92df4d566","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["vi_data = pd.read_csv('vi.tsv', sep='\\t')\n","vi_data.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['unigram', 'syllable', 'word'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"qGed33SDv8mH"},"source":["vi_bpe = open('test.bpe.vi','r').read().splitlines() + open('dev.bpe.vi','r').read().splitlines() + open('train.bpe.vi','r').read().splitlines()\n","vi_data['bpe'] = vi_bpe\n","vi_data = vi_data[['bpe','unigram', 'syllable', 'word']]\n","vi_data.to_csv('new.vi.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFQVIeglu33K"},"source":["def tag_subword(bpe_filename, factor_filename, outfilename):\n","    \"\"\"\n","    function tags subwords\n","    input: bpe_filename, bpe.ru file,\n","    input: factor_filename, tsv file\n","    output: outfilename, tsv file\n","\n","    \"\"\"\n","     \n","    bpe_sentences = open(bpe_filename, 'r').read().splitlines()\n","    factor_names = ['le', 'ihead', 'head', 'deprel', 'upos', 'feats']\n","    factor_sequences = pd.read_csv(factor_filename, sep='\\t')\n","\n","    trgs = factor_sequences['vi']\n","    factor_sequences = factor_sequences[factor_names]\n","\n","    bpeNfactor_sentences = []\n","\n","    j = 0\n","\n","    for sentence in bpe_sentences:\n","        factor_sequence = factor_sequences.iloc[j].to_list()\n","        factor_sequence = [e.split(' ') for e in factor_sequence]\n","        factor_sequence = pd.DataFrame(data=factor_sequence)\n","        state = \"O\"\n","        i = 0\n","        tag_sentence = []\n","        \n","        for word in sentence.split():\n","            factors = factor_sequence.iloc[:,i].to_list()\n","            if word.endswith('@@'):\n","                if state == \"O\" or state == \"E\":\n","                    state = \"B\"\n","                elif state == \"B\" or state == \"I\":\n","                    state = \"I\"\n","            else:\n","                i += 1\n","                if state == \"B\" or state == \"I\":\n","                    state = \"E\"\n","                else:\n","                    state = \"O\"\n","            tag_sentence.append([word, state] + factors)\n","        \n","        tag_sequence = pd.DataFrame(columns=['ru','subtag']+ factor_names, data=tag_sentence)\n","        tag_sequence = [tag_sequence[factor].str.cat(sep=' ') for factor in tag_sequence]\n","        bpeNfactor_sentences.append(tag_sequence)\n","\n","        j += 1\n","    result = pd.DataFrame(columns=['ru','subtag']+ factor_names, data=bpeNfactor_sentences)\n","    result['vi'] = trgs \n","    result.to_csv(outfilename, sep='\\t',index=False)\n","\n","tag_subword('test.bpe.ru', 'test.tsv', 'test.sub.tsv')\n","tag_subword('dev.bpe.ru', 'dev.tsv', 'dev.sub.tsv')\n","tag_subword('train.bpe.ru', 'train.tsv', 'train.sub.tsv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-aHIALUFIgfi","executionInfo":{"status":"error","timestamp":1588924293972,"user_tz":-420,"elapsed":3186,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"f7c4765a-f551-44f9-f346-53129fd31940","colab":{"base_uri":"https://localhost:8080/"}},"source":["def tag_unigram_subword(unigram_filename, factor_filename, outfilename):\n","    \"\"\"\n","    function tags subwords\n","    input: unigram_filename, unigram.ru file,\n","    input: factor_filename, tsv file\n","    output: outfilename, tsv file\n","\n","    \"\"\"\n","    \n","    unigram_sentences = open(unigram_filename, 'r').read().splitlines()\n","    factor_names = ['le', 'ihead', 'head', 'deprel', 'upos', 'feats']\n","    factor_sequences = pd.read_csv(factor_filename, sep='\\t')\n","\n","    factor_sequences = factor_sequences[factor_names]\n","\n","    unigramNfactor_sentences = []\n","\n","    j = 0\n","\n","    for sentence in unigram_sentences:\n","        factor_sequence = factor_sequences.iloc[j].to_list()\n","        factor_sequence = [e.split(' ') for e in factor_sequence]\n","        factor_sequence = pd.DataFrame(data=factor_sequence)\n","        #print(factor_sequence.shape)\n","        state = \"O\"\n","        i = 0\n","        tag_sentence = []\n","\n","        # print(f\"The number of '▁' is {sentence.count('▁')}\")\n","        # print(f\"The number of whole words is {factor_sequence.shape[1]}\")\n","        # print('    ')\n","        \n","        words = sentence.split()\n","        for k, word in enumerate(words[:-1]):\n","            #print(i)\n","            factors = factor_sequence.iloc[:,i].to_list()\n","            if len(factors) < 6:\n","                print()\n","            \n","            if word.startswith('▁'):\n","                if words[k+1].startswith('▁'):\n","                    state = \"O\"\n","                    i += 1\n","                else:\n","                    state = \"B\"\n","            else:\n","                if words[k+1].startswith('▁'):\n","                    state == \"E\"\n","                    i += 1\n","                else:\n","                    state = \"I\"\n","                \n","            tag_sentence.append([word, state] + factors)\n","        \n","        if words[-1].startswith('▁'):\n","            state = \"O\"\n","        else:\n","            state = \"E\"\n","        factors = factor_sequence.iloc[:,-1].to_list()\n","        tag_sentence.append([words[-1], state] + factors)\n","\n","\n","        tag_sequence = pd.DataFrame(columns=['ru','subtag']+ factor_names, data=tag_sentence)\n","        tag_sequence = [tag_sequence[factor].str.cat(sep=' ') for factor in tag_sequence]\n","        unigramNfactor_sentences.append(tag_sequence)\n","\n","        j += 1\n","    result = pd.DataFrame(columns=['ru','subtag']+ factor_names, data=unigramNfactor_sentences)\n","    result.to_csv(outfilename, sep='\\t',index=False)\n","\n","tag_unigram_subword('dev.unigram.ru', 'dev.tsv', 'dev.unigram.ru.tsv')\n","tag_unigram_subword('train.unigram.ru', 'train.tsv', 'train.unigram.ru.tsv')\n","tag_unigram_subword('test.unigram.ru', 'test.tsv', 'test.unigram.ru.tsv')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-acb6d2f478a2>\"\u001b[0;36m, line \u001b[0;32m38\u001b[0m\n\u001b[0;31m    if word.startswith('▁'):\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"]}]},{"cell_type":"code","metadata":{"id":"3H_3UiOsLhO7"},"source":["test_unigram_ru = pd.read_csv('test.unigram.ru.tsv', sep='\\t')\n","dev_unigram_ru = pd.read_csv('dev.unigram.ru.tsv', sep='\\t')\n","train_unigram_ru = pd.read_csv('train.unigram.ru.tsv', sep='\\t')\n","unigram_ru = pd.concat([test_unigram_ru, dev_unigram_ru, train_unigram_ru])\n","unigram_ru.to_csv('unigram.ru.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pEr9Qu3Xce6H"},"source":["x = pd.read_csv('unigram.ru.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PL-eOW2QfZy4","executionInfo":{"status":"ok","timestamp":1588844329855,"user_tz":-420,"elapsed":957,"user":{"displayName":"Chi Thien Nguyen","photoUrl":"","userId":"17370809216906661158"}},"outputId":"e50171d3-627f-4b0e-bc7c-ed682b4047b3","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ru', 'subtag', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"CMZqXv6tg_R3","executionInfo":{"status":"ok","timestamp":1588844580408,"user_tz":-420,"elapsed":996,"user":{"displayName":"Chi Thien Nguyen","photoUrl":"","userId":"17370809216906661158"}},"outputId":"74bd5c20-145a-46ee-e935-177f00bb7a97","colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["x.iloc[0,:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ru        ▁ген и ально сть ▁и он е ско ▁заключал ась ▁в ...\n","subtag    B I I I B I I I B B O B B B B O O O B B B I I O O\n","le        гениальность гениальность гениальность гениаль...\n","ihead     3 3 3 3 3 3 3 3 0 0 5 3 3 5 5 6 11 10 11 11 7 ...\n","head      заключаться заключаться заключаться заключатьс...\n","deprel    nsubj nsubj nsubj nsubj advmod advmod advmod a...\n","upos      NOUN NOUN NOUN NOUN ADV ADV ADV ADV VERB VERB ...\n","feats     Animacy=Inan,Case=Nom,Gender=Fem,Number=Sing A...\n","Name: 0, dtype: object"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"B3kujOZJx64s"},"source":["##Factor"]},{"cell_type":"code","metadata":{"id":"bxS31AvAx45T"},"source":["# !pip install stanza\n","if factored:\n","    import stanza\n","    stanza.download('ru')\n","    nlp = stanza.Pipeline(lang='ru', processors='tokenize,mwt,pos,lemma,depparse')\n","    def __words2factors(sentence, nlp=nlp):\n","        doc = nlp(sentence)\n","        result = [# ' '.join([word.lemma for sent in doc.sentences for word in sent.words]),\n","                ' '.join([str(word.head) for sent in doc.sentences for word in sent.words]),\n","                ' '.join([sent.words[word.head-1].lemma for sent in doc.sentences for word in sent.words]),\n","                ' '.join([word.deprel for sent in doc.sentences for word in sent.words]),\n","                ' '.join([word.upos for sent in doc.sentences for word in sent.words]),\n","                ' '.join([word.feats if word.feats else \"_\" for sent in doc.sentences for word in sent.words]).replace('|', ',')]\n","        return result\n","\n","\n","    def words2factors(filename, newfilename):\n","        data = pd.read_csv(filename, sep='\\t')\n","        features = [__words2factors(line) for line in data['ru']]\n","        features = pd.DataFrame(columns=['ihead', 'head', 'deprel', 'upos', 'feats'], data=features)\n","        x = data.join(features)\n","        x = x[['ru', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'vi']]\n","        x.to_csv(newfilename, sep='\\t', index=False)\n","\n","    start_time = time.time()\n","    words2factors('dev.RuLeVi.tsv', 'dev.tsv')\n","    print('...dev')\n","    words2factors('test.RuLeVi.tsv', 'test.tsv')\n","    print('...test')\n","    words2factors('train.RuLeVi.tsv', 'train.tsv')\n","    end_time = time.time()        \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    print(f'time in minutes: {epoch_mins}')\n","\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"owMokvRIL-wg","executionInfo":{"status":"ok","timestamp":1592465897526,"user_tz":-420,"elapsed":6509,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"bde8df1d-3c23-44d6-eeaf-c4277a6ad67f","colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["!pip install stanza"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting stanza\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/9c/60689521a971a57dd02d2925105efedefa9dccd76c9a0b92566683d43e89/stanza-1.0.1-py3-none-any.whl (193kB)\n","\r\u001b[K     |█▊                              | 10kB 19.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from stanza) (2.23.0)\n","Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from stanza) (1.5.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stanza) (4.41.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from stanza) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stanza) (1.18.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (2020.4.5.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->stanza) (3.0.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->stanza) (0.16.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->stanza) (47.1.1)\n","Installing collected packages: stanza\n","Successfully installed stanza-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AmluVZWvMGb9","executionInfo":{"status":"ok","timestamp":1592465923677,"user_tz":-420,"elapsed":23215,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"479d7f5c-c0b6-485e-f04e-6fcf424e75d4","colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["import stanza\n","stanza.download('vi')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.0.0.json: 115kB [00:00, 10.4MB/s]                    \n","2020-06-18 07:38:24 INFO: Downloading default packages for language: vi (Vietnamese)...\n","Downloading http://nlp.stanford.edu/software/stanza/1.0.0/vi/default.zip: 100%|██████████| 216M/216M [00:13<00:00, 15.8MB/s]\n","2020-06-18 07:38:42 INFO: Finished downloading models and saved to /root/stanza_resources.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Lga7La5ZNQZ9"},"source":["nlp = stanza.Pipeline(lang='vi', processors='tokenize,pos,lemma,depparse')\n","sentence = 'khắp châu phi , trung quốc đang tài trợ và xây dựng cơ sở hạ tầng cơ bản . đầu tư vào giáo dục là vấn đề sống còn đối với mỹ latinh và caribê .'\n","doc = nlp(sentence)\n","print(doc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Siy-wYvBX2sx"},"source":["doc.sentences[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMLF81FvNwmV"},"source":["nlp = stanza.Pipeline(lang='vi', processors='tokenize,pos,ner')\n","sentence = 'đầu tư vào giáo dục là vấn đề sống còn đối với mỹ latinh và caribê .'\n","doc = nlp(sentence)\n","print(doc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sTUV2jfBJ6Q9"},"source":["# !pip install stanza\n","import stanza\n","stanza.download('vi')\n","nlp = stanza.Pipeline(lang='vi', processors='tokenize,mwt,pos,lemma,depparse,ner')\n","sentence = 'đầu tư vào giáo dục là vấn đề sống còn đối với mỹ latinh và caribê .'\n","doc = nlp(sentence)\n","\n","def __words2factors(sentence, nlp=nlp):\n","    doc = nlp(sentence)\n","    result = [# ' '.join([word.lemma for sent in doc.sentences for word in sent.words]),\n","            ' '.join([str(word.head) for sent in doc.sentences for word in sent.words]),\n","            ' '.join([sent.words[word.head-1].lemma for sent in doc.sentences for word in sent.words]),\n","            ' '.join([word.deprel for sent in doc.sentences for word in sent.words]),\n","            ' '.join([word.upos for sent in doc.sentences for word in sent.words]),\n","            ' '.join([word.feats if word.feats else \"_\" for sent in doc.sentences for word in sent.words]).replace('|', ',')]\n","    return result\n","\n","\n","def words2factors(filename, newfilename):\n","    data = pd.read_csv(filename, sep='\\t')\n","    features = [__words2factors(line) for line in data['ru']]\n","    features = pd.DataFrame(columns=['ihead', 'head', 'deprel', 'upos', 'feats'], data=features)\n","    x = data.join(features)\n","    x = x[['ru', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'vi']]\n","    x.to_csv(newfilename, sep='\\t', index=False)\n","\n","start_time = time.time()\n","words2factors('dev.RuLeVi.tsv', 'dev.tsv')\n","print('...dev')\n","words2factors('test.RuLeVi.tsv', 'test.tsv')\n","print('...test')\n","words2factors('train.RuLeVi.tsv', 'train.tsv')\n","end_time = time.time()        \n","epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","print(f'time in minutes: {epoch_mins}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Eix_kjRd9CW","executionInfo":{"status":"ok","timestamp":1592466609360,"user_tz":-420,"elapsed":22170,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"6269f01a-4243-460c-b49e-890eaf3aa1d6","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["%%shell\n","cd /content\n","git clone https://github.com/vncorenlp/VnCoreNLP.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'VnCoreNLP'...\n","remote: Enumerating objects: 212, done.\u001b[K\n","remote: Total 212 (delta 0), reused 0 (delta 0), pack-reused 212\u001b[K\n","Receiving objects: 100% (212/212), 214.21 MiB | 13.54 MiB/s, done.\n","Resolving deltas: 100% (76/76), done.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"cHmZotyueLxs","executionInfo":{"status":"ok","timestamp":1592466556453,"user_tz":-420,"elapsed":7191,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"13dbe358-fe01-4d75-b501-c480668f7eb6","colab":{"base_uri":"https://localhost:8080/","height":292}},"source":["!pip install vncorenlp"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.4.5.2)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.9)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645935 sha256=6ab59249a9643afbf18ae2312f18c44aa3a5bb894b880e5583136a786a011cd9\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-_rEovapeRj0"},"source":["from vncorenlp import VnCoreNLP\n","annotator = VnCoreNLP(\"/content/VnCoreNLP/VnCoreNLP-1.1.1.jar\", annotators=\"wseg,pos,ner,parse\", max_heap_size='-Xmx2g') \n","\n","# Input \n","# text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n","# To perform word segmentation, POS tagging, NER and then dependency parsing\n","# annotated_text = annotator.annotate(text)\n","\n","# To perform word segmentation only\n","# word_segmented_text = annotator.tokenize(text) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yzZyB9kehSD","executionInfo":{"status":"ok","timestamp":1592467010936,"user_tz":-420,"elapsed":1586,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"29a110f9-e1b0-42b7-d01d-997005aa2004","colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["text = \"Ông Nguyễn Khắc Chúc  đang làm việc tại Đại học Quốc gia Hà Nội. Bà Lan, vợ ông Chúc, cũng làm việc tại đây.\"\n","text = 'điện Kremlin đã làm_ngơ trước sự ân_xá của Kadyrov , đối_với các cựu_chiến_binh và việc đưa họ vào lực_lượng dân_quân .'\n","text = 'khắp châu phi , trung quốc đang tài trợ và xây dựng cơ sở hạ tầng cơ bản .'\n","text = 'đầu tư vào giáo dục là vấn đề sống còn đối với mỹ latinh và caribê .'\n","word_segmented_text = annotator.tokenize(text)\n","annotated_text = annotator.annotate(text)\n","print(word_segmented_text)\n","print(annotated_text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[['đầu_tư', 'vào', 'giáo_dục', 'là', 'vấn_đề', 'sống_còn', 'đối_với', 'mỹ', 'latinh', 'và', 'caribê', '.']]\n","{'sentences': [[{'index': 1, 'form': 'đầu_tư', 'posTag': 'V', 'nerLabel': 'O', 'head': 0, 'depLabel': 'root'}, {'index': 2, 'form': 'vào', 'posTag': 'E', 'nerLabel': 'O', 'head': 1, 'depLabel': 'loc'}, {'index': 3, 'form': 'giáo_dục', 'posTag': 'N', 'nerLabel': 'O', 'head': 2, 'depLabel': 'pob'}, {'index': 4, 'form': 'là', 'posTag': 'V', 'nerLabel': 'O', 'head': 1, 'depLabel': 'vmod'}, {'index': 5, 'form': 'vấn_đề', 'posTag': 'N', 'nerLabel': 'O', 'head': 4, 'depLabel': 'vmod'}, {'index': 6, 'form': 'sống_còn', 'posTag': 'V', 'nerLabel': 'O', 'head': 5, 'depLabel': 'nmod'}, {'index': 7, 'form': 'đối_với', 'posTag': 'E', 'nerLabel': 'O', 'head': 5, 'depLabel': 'nmod'}, {'index': 8, 'form': 'mỹ', 'posTag': 'N', 'nerLabel': 'O', 'head': 7, 'depLabel': 'pob'}, {'index': 9, 'form': 'latinh', 'posTag': 'N', 'nerLabel': 'O', 'head': 8, 'depLabel': 'nmod'}, {'index': 10, 'form': 'và', 'posTag': 'Cc', 'nerLabel': 'O', 'head': 8, 'depLabel': 'coord'}, {'index': 11, 'form': 'caribê', 'posTag': 'N', 'nerLabel': 'O', 'head': 10, 'depLabel': 'conj'}, {'index': 12, 'form': '.', 'posTag': 'CH', 'nerLabel': 'O', 'head': 1, 'depLabel': 'punct'}]]}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VpnmePMXPVVv"},"source":["test = pd.read_csv('test.tsv', sep='\\t')\n","dev = pd.read_csv('dev.tsv', sep='\\t')\n","train = pd.read_csv('train.tsv', sep='\\t')\n","data = pd.concat([test, dev, train])[['ru', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats']]\n","data.to_csv('word.ru.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_YLMrMrxP59P","executionInfo":{"status":"ok","timestamp":1588844844935,"user_tz":-420,"elapsed":945,"user":{"displayName":"Chi Thien Nguyen","photoUrl":"","userId":"17370809216906661158"}},"outputId":"4969d4ad-d3e5-412b-a101-b7112bfd330b","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ru', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'vi'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"WSx9fFt5RWRo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pACBb31cR3Aj","executionInfo":{"status":"ok","timestamp":1588823820998,"user_tz":-420,"elapsed":1104,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"4e335381-8838-486f-a929-36e57a45b649","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33027, 8)"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"qayy6PQDSajN","executionInfo":{"status":"ok","timestamp":1588823968249,"user_tz":-420,"elapsed":998,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"3c951a2e-7124-4ef6-9bc5-33893602349f","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['ru', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats', 'vi'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"sQq-4ZgaS3ov"},"source":["bpe_test = pd.read_csv('test.sub.tsv', sep='\\t')\n","bpe_dev = pd.read_csv('dev.sub.tsv', sep='\\t')\n","bpe_train = pd.read_csv('train.sub.tsv', sep='\\t')\n","bpe_data = pd.concat([bpe_test, bpe_dev, bpe_train])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fjHb6CfzgqFl"},"source":["bpe_data = bpe_data[['ru', 'subtag', 'le', 'ihead', 'head', 'deprel', 'upos', 'feats']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1Hkr-Z_UkF6"},"source":["bpe_data.to_csv('bpe.ru.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"arS3twH_VzhG","executionInfo":{"status":"ok","timestamp":1588844628326,"user_tz":-420,"elapsed":1000,"user":{"displayName":"Chi Thien Nguyen","photoUrl":"","userId":"17370809216906661158"}},"outputId":"49d892cb-df04-4ac8-c6cd-6be70614f017","colab":{"base_uri":"https://localhost:8080/"}},"source":["bpe_data.iloc[0,:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ru        г@@ ени@@ аль@@ ность и@@ о@@ нес@@ ко заключа...\n","subtag          B I I E B I I E O O O B E O O O O B E B E O\n","le        гениальность гениальность гениальность гениаль...\n","ihead      3 3 3 3 3 3 3 3 0 5 3 5 5 6 11 10 11 7 7 11 11 3\n","head      заключаться заключаться заключаться заключатьс...\n","deprel    nsubj nsubj nsubj nsubj advmod advmod advmod a...\n","upos      NOUN NOUN NOUN NOUN ADV ADV ADV ADV VERB ADP N...\n","feats     Animacy=Inan,Case=Nom,Gender=Fem,Number=Sing A...\n","Name: 0, dtype: object"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"ZapXPxA8kyWi"},"source":["x = open('test.unigram.vi', 'r').read().splitlines()\n","y = open('dev.unigram.vi', 'r').read().splitlines()\n","z = open('train.unigram.vi', 'r').read().splitlines()\n","xyz = x + y + z\n","\n","x = open('test.vi', 'r').read().splitlines()\n","y = open('dev.vi', 'r').read().splitlines()\n","z = open('train.vi', 'r').read().splitlines()\n","xyz1 = x + y + z\n","\n","x = open('__test.vi', 'r').read().splitlines()\n","y = open('__dev.vi', 'r').read().splitlines()\n","z = open('__train.vi', 'r').read().splitlines()\n","xyz2 = x + y + z\n","\n","pd.DataFrame({'unigram':xyz, 'syllable': xyz1, 'word': xyz2}).to_csv('vi.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"39b3notKl-q7"},"source":["vi = pd.read_csv('vi.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_dWSoelrmHnV","executionInfo":{"status":"ok","timestamp":1588845916306,"user_tz":-420,"elapsed":1083,"user":{"displayName":"Chi Thien Nguyen","photoUrl":"","userId":"17370809216906661158"}},"outputId":"18f6c507-0189-4818-cbe8-54b7b99c6c75","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["vi.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(33027, 3)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"IM0oHNZ_xJUB"},"source":["ruvi_dict = defaultdict(lambda : '<unk>')\n","ruvi_prob = defaultdict(lambda : 0.0)\n","e2f = open('lex.e2f', 'r').read().splitlines()\n","for line in e2f:\n","    ruword, viword, value = line.split(' ')\n","    fvalue = float(value)\n","    if fvalue > ruvi_prob[ruword]:\n","        ruvi_dict[ruword] = viword\n","        ruvi_prob[ruword] = fvalue"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CJ5amr8HU5XJ"},"source":["ru_data = pd.read_csv('word.nowordtranslation.ru.tsv', sep='\\t')\n","ru_sentences = ru_data['ru'].to_list()\n","ru_words = [sentence.split(' ') for sentence in ru_sentences]\n","vi_words = [[ruvi_dict[word] for word in sentence] for sentence in ru_words]\n","vi_sentences = [' '.join(sentence) for sentence in vi_words]\n","\n","columns = list(ru_data.columns)\n","ru_data['wordtranslation'] = vi_sentences\n","ru_data = ru_data[columns + ['wordtranslation']]\n","ru_data.to_csv('word.ru.tsv', sep='\\t', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxWnLyfCvPQI"},"source":["import pickle\n","with open('ruvi_dict.pickle', 'wb') as handle:\n","    pickle.dump(ruvi_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tj9SP_s6vfp1"},"source":["with open('ruvi_dict.pickle', 'rb') as handle:\n","    b = pickle.load(handle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wlaheuj5uvkL","executionInfo":{"status":"ok","timestamp":1589100541298,"user_tz":-420,"elapsed":1295,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"a1771c16-46fd-4dd0-c509-2514be457511","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(ruvi_dict.keys())[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['потенциальных', 'диаса', 'саммитах', 'проигнорированы', '1989']"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"rP0vY_rpvpNu","executionInfo":{"status":"ok","timestamp":1589100755274,"user_tz":-420,"elapsed":1251,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"7b126184-5ee7-4128-8e98-f81193b367eb","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(b.keys())[:5]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['потенциальных', 'диаса', 'саммитах', 'проигнорированы', '1989']"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"6Unmpedqu6Ui","executionInfo":{"status":"ok","timestamp":1589100865395,"user_tz":-420,"elapsed":1376,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"03f71104-035a-4542-f2cb-8d6c07db6930","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["b['саммитах']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'hội_nghị_thượng_đỉnh'"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"r8NGq7MpzLQs"},"source":["allru = pd.read_csv('word.ru.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"svW5sZTGzWI3","executionInfo":{"status":"ok","timestamp":1589117571264,"user_tz":-420,"elapsed":1017,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"8c4b3f2d-5a61-4427-889b-b79454703594","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["len(allru.columns)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"6nug7DGR7Pe1"},"source":["!head __train.vi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FzZw20_Wb03z"},"source":["SMT"]},{"cell_type":"code","metadata":{"id":"uQHPLRmo96vr","executionInfo":{"status":"ok","timestamp":1591754712154,"user_tz":-420,"elapsed":11567,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"c4eb26a7-a453-47fa-b591-6a567b6f1e68","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["subprocess.run(['unzip', '/content/gdrive/My Drive/tools/smt.zip', '-d', '/'])\n","subprocess.run(['unzip', '/content/gdrive/My Drive/tools/mgiza.zip', '-d', '/'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args=['unzip', '/content/gdrive/My Drive/tools/mgiza.zip', '-d', '/'], returncode=0)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"aPdwzjvB-eai","executionInfo":{"status":"ok","timestamp":1591755912926,"user_tz":-420,"elapsed":1055,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"ad7d7f91-d652-4fab-e9fc-174f668c740a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/My Drive/nmt_models/NewsLinguisticFeaturesALL'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"l0o7calt-iBr"},"source":["!unzip smt_result.zip -d /"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nNQdbKSNn-wR"},"source":["!zcat /content/working/train/model/phrase-table.gz > phrase-table.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nJkD_eWT5411"},"source":["!head -500 phrase-table.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lNwnjCj8GrW"},"source":["pt = open('phrase-table.txt', 'r').read().splitlines()\n","wpt = open('word-phrase-table.txt', 'w')\n","for line in pt:\n","    parts = line.split(' ||| ')\n","    ru, vi = parts[0], parts[1]\n","    #print(parts[2])\n","    score = float(parts[2].split(' ')[2])\n","    if len(parts[0].split(' ')) == 1:\n","        wpt.write(f'{ru} ||| {vi} ||| {score} \\n')\n","wpt.close()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lS2GN8KdCadU"},"source":["!cat word-phrase-table.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"l3Bb4lzd-U4T","executionInfo":{"status":"ok","timestamp":1592476138011,"user_tz":-420,"elapsed":1627,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"5907fb1c-e081-4ee0-b086-88029e05b552","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["float('2.50465e-11')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2.50465e-11"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"LkBfq3fHqDVd"},"source":["!zcat /content/working/train/model/extract.sorted.gz | tail -500"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PSHhp5Qa_I6Z","executionInfo":{"status":"ok","timestamp":1591756359420,"user_tz":-420,"elapsed":144397,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"ba7b3ae6-3578-46d3-e202-d28ceebcaadd","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["%%shell\n","cd /content/working/\n","/content/tools/moses/bin/moses -f /content/working/mert-work/moses.ini < test.ru > __pred_test.smt.vi 2> test.out"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"GOXfseseCB25"},"source":["DataCenter.detokenize('/content/working/__pred_test.smt.vi', '/content/working/pred_test.smt.vi')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8yqNSYZrCS8L","executionInfo":{"status":"ok","timestamp":1591756567539,"user_tz":-420,"elapsed":1730,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"e68884fc-472a-41d4-d026-9d868875ef6a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def evaluate_bleu_nltk(reference_filename, hypothesis_filename):\n","    references = open(reference_filename).read().splitlines()\n","    references = [line.split(' ') for line in references]\n","    hypotheses = open(hypothesis_filename, 'r').read().splitlines()\n","    hypotheses = [line.split(' ') for line in hypotheses]\n","\n","    list_refs = [[r] for r in references]\n","\n","    return corpus_bleu(list_refs, hypotheses)\n","\n","#cb = evaluate_bleu_nltk(reference_filename='test.vi', \n","#                        hypothesis_filename=f'pred_{model.name}.vi')\n","cb = evaluate_bleu_nltk(reference_filename='test.vi', \n","                        hypothesis_filename='/content/working/pred_test.smt.vi')\n","print(cb)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.445131941036839\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bAzl_nhgDD1s"},"source":["!head '/content/working/pred_test.smt.vi'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C2NfRh_3b4Lz"},"source":["!mkdir /content/working"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOvuPOWWcJh9","executionInfo":{"status":"ok","timestamp":1589111728316,"user_tz":-420,"elapsed":1025,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"c4eebbea-ff3b-4803-b96c-a2656ecbb52e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/working"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/working\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LFGCqCudcLBF"},"source":["!cp /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL/train.ru /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL/__train.vi /content/working/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rI0tWBAxj1IP"},"source":["!cp /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL/dev.ru /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL/__dev.vi /content/working/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VaN_jstOc1IK"},"source":["!head /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL/__train.vi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WQ9e3uY3dDAl","executionInfo":{"status":"ok","timestamp":1589113778391,"user_tz":-420,"elapsed":3306,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"74b983c3-b8de-4755-8297-91dd991ea4ef","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!ls /content/working/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dev.ru\t  train\t\t   __train.blm.vi  __train.vi\n","__dev.vi  __train.arpa.vi  __train.ru\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kKoNQGUUdnXo","executionInfo":{"status":"ok","timestamp":1589112165972,"user_tz":-420,"elapsed":5515,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"cd779b8c-dc5a-42ca-d8e5-2048df04c2ef","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import subprocess\n","subprocess.run(['unzip', '/content/gdrive/My Drive/tools/smt.zip', '-d', '/'])\n","subprocess.run(['unzip', '/content/gdrive/My Drive/tools/mgiza.zip', '-d', '/'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CompletedProcess(args=['unzip', '/content/gdrive/My Drive/tools/mgiza.zip', '-d', '/'], returncode=0)"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"PALNINVHdPXH"},"source":["#Language Model Training\n","!/content/tools/moses/bin/lmplz -o 3 < __train.vi > __train.arpa.vi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mjtg_DAKd6zl"},"source":["#binarise (for faster loading)\n","!/content/tools/moses/bin/build_binary __train.arpa.vi __train.blm.vi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C1Qol20EebM2"},"source":["#Training the Translation System\n","!/content/tools/moses/scripts/training/train-model.perl -mgiza -root-dir train -corpus __train -f ru -e vi -alignment grow-diag-final-and -reordering msd-bidirectional-fe -lm 0:3:/content/working/__train.blm.vi:8 -external-bin-dir /content/mgiza/mgizapp/inst"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zt4zafGFjfSk","executionInfo":{"status":"ok","timestamp":1589116570075,"user_tz":-420,"elapsed":2704403,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"5dec6c67-4fd7-4d4a-9820-62edb3d90268","colab":{"base_uri":"https://localhost:8080/","height":17}},"source":["%%shell\n","cd /content/working\n","/content/tools/moses/scripts/training/mert-moses.pl dev.ru __dev.vi /content/tools/moses/bin/moses train/model/moses.ini --mertdir /content/tools/moses/bin --decoder-flags=\"-threads 4\" &> mert.out"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"36g1aFzvvFWW"},"source":["%%shell\n","cd /content\n","zip -r smt_result.zip /content/working\n","cp /content/smt_result.zip /content/gdrive/My\\ Drive/nmt_models/NewsLinguisticFeaturesALL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lYSbYbMrAZ9"},"source":["import pandas as pd\n","bpeRU = pd.read_csv('bpe.ru.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g1THtHuouAbE"},"source":["bpeRU = pd.read_csv('bpe.ru.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jDhuJYa3roxQ","executionInfo":{"status":"ok","timestamp":1589451521070,"user_tz":-420,"elapsed":978,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"1728231a-0bd2-4b3a-c9f8-ccf292b6448b","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["bpeRU['ru'].iloc[2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'ответ на первонача@@ льную а@@ гре@@ сси@@ ю хезбол@@ лы , как и ответ@@ ные военные действия израиля в га@@ зе являются не@@ пропорциональ@@ но суро@@ выми .'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"2NBX60OpuLOl"},"source":["unigramRU = pd.read_csv('unigram.ru.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jQHwA55JuQ1z","executionInfo":{"status":"ok","timestamp":1589452027629,"user_tz":-420,"elapsed":1082,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"68a41b4a-e397-4304-bfdc-e0079fdde843","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["unigramRU['ru'].iloc[2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'▁ответ ▁на ▁первоначальн ую ▁агресси ю ▁хезболл ы ▁, ▁как ▁и ▁ответ ные ▁военны е ▁действия ▁израил я ▁в ▁газ е ▁являются ▁не про пор ц и он ально ▁с у ров ыми ▁.'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"Sm6MoYZ9ry1m"},"source":["VI = pd.read_csv('new.vi.tsv', sep='\\t')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6B22CHjJsEVu","executionInfo":{"status":"ok","timestamp":1589451477040,"user_tz":-420,"elapsed":1056,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"167a8434-dae9-4335-fb97-662341f081cb","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["VI.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['bpe', 'unigram', 'syllable', 'word'], dtype='object')"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"0gsjcDqer5c1","executionInfo":{"status":"ok","timestamp":1589451501219,"user_tz":-420,"elapsed":835,"user":{"displayName":"Nguyễn Chí Thiện","photoUrl":"","userId":"17428228934276242215"}},"outputId":"293f1267-95de-4a4a-a372-a157e8c9c6f1","colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["VI['bpe'].iloc[2]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'phản ứng trước sự gây h@@ ấn ban đầu của h@@ e@@ z@@ bo@@ l@@ la@@ h , cũng như hành động quân sự trả đ@@ ũ@@ a của israel ở gaza , rất khắc ngh@@ iệt . '"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"QlVsMcwmr9FN"},"source":[""],"execution_count":null,"outputs":[]}]}